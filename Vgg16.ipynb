{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":4449179,"sourceType":"datasetVersion","datasetId":2605423}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport cv2\nimport pickle\nimport random as rnd\nimport numpy as np\nimport pandas as pd","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-11T21:47:42.298587Z","iopub.execute_input":"2024-05-11T21:47:42.298983Z","iopub.status.idle":"2024-05-11T21:47:42.303693Z","shell.execute_reply.started":"2024-05-11T21:47:42.298951Z","shell.execute_reply":"2024-05-11T21:47:42.302795Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"# Image Preprocessing Function with default image size\ndef preprocess(image_path, image_size=224):\n    image = cv2.imread(image_path)\n    image = cv2.resize(image, (image_size, image_size))\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    image = image / 255.0\n    return torch.tensor(image).permute(2, 0, 1)","metadata":{"execution":{"iopub.status.busy":"2024-05-11T21:47:42.307271Z","iopub.execute_input":"2024-05-11T21:47:42.307802Z","iopub.status.idle":"2024-05-11T21:47:42.318452Z","shell.execute_reply.started":"2024-05-11T21:47:42.307757Z","shell.execute_reply":"2024-05-11T21:47:42.317642Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"# Create DataFrame from Directory Structure\ndef create_dataframe(datadir):\n    result_dataframe = []\n    for train_test_name in os.listdir(datadir):\n        label_dir = os.path.join(datadir, train_test_name)\n        for label_name in os.listdir(label_dir):\n            image_dir = os.path.join(label_dir, label_name)\n            for image_path in os.listdir(image_dir):\n                record_dict = {\n                    'is_train': 0 if train_test_name == 'test' else 1,\n                    'label': label_name.replace('healthy', 'Healthy'),\n                    'image_path': os.path.join(image_dir, image_path)\n                }\n                result_dataframe.append(record_dict)\n    return result_dataframe\n","metadata":{"execution":{"iopub.status.busy":"2024-05-11T21:47:42.319811Z","iopub.execute_input":"2024-05-11T21:47:42.320084Z","iopub.status.idle":"2024-05-11T21:47:42.329481Z","shell.execute_reply.started":"2024-05-11T21:47:42.320061Z","shell.execute_reply":"2024-05-11T21:47:42.328603Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"# Data Loading and Preparation\ndatadir = '/kaggle/input/lungs-disease-data/data'\nresult_dataframe = create_dataframe(datadir)\nresult_dataframe = pd.DataFrame.from_records(result_dataframe)  # Ensure this conversion is correctly done\ntrain_dataframe = result_dataframe[result_dataframe['is_train'] == 1].drop('is_train', axis=1)\ntest_dataframe = result_dataframe[result_dataframe['is_train'] == 0].drop('is_train', axis=1)","metadata":{"execution":{"iopub.status.busy":"2024-05-11T21:47:42.330574Z","iopub.execute_input":"2024-05-11T21:47:42.330924Z","iopub.status.idle":"2024-05-11T21:47:42.349054Z","shell.execute_reply.started":"2024-05-11T21:47:42.330889Z","shell.execute_reply":"2024-05-11T21:47:42.348336Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"# Label Encoding\nfrom sklearn.preprocessing import LabelEncoder\n\nle = LabelEncoder()\ntrain_dataframe['label'] = le.fit_transform(train_dataframe['label'].values)\ntest_dataframe['label'] = le.transform(test_dataframe['label'].values)","metadata":{"execution":{"iopub.status.busy":"2024-05-11T21:47:42.350959Z","iopub.execute_input":"2024-05-11T21:47:42.351232Z","iopub.status.idle":"2024-05-11T21:47:42.357057Z","shell.execute_reply.started":"2024-05-11T21:47:42.351209Z","shell.execute_reply":"2024-05-11T21:47:42.356091Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"code","source":"train_dataframe['label'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2024-05-11T21:47:42.358285Z","iopub.execute_input":"2024-05-11T21:47:42.358775Z","iopub.status.idle":"2024-05-11T21:47:42.370679Z","shell.execute_reply.started":"2024-05-11T21:47:42.358742Z","shell.execute_reply":"2024-05-11T21:47:42.369832Z"},"trusted":true},"execution_count":60,"outputs":[{"execution_count":60,"output_type":"execute_result","data":{"text/plain":"label\n1    111\n0     70\n2     70\nName: count, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"test_dataframe['label'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2024-05-11T21:47:42.371835Z","iopub.execute_input":"2024-05-11T21:47:42.372210Z","iopub.status.idle":"2024-05-11T21:47:42.381394Z","shell.execute_reply.started":"2024-05-11T21:47:42.372183Z","shell.execute_reply":"2024-05-11T21:47:42.380569Z"},"trusted":true},"execution_count":61,"outputs":[{"execution_count":61,"output_type":"execute_result","data":{"text/plain":"label\n1    26\n0    20\n2    20\nName: count, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"test_dataframe['label'].value_counts().keys() == train_dataframe['label'].value_counts().keys()","metadata":{"execution":{"iopub.status.busy":"2024-05-11T21:47:42.382713Z","iopub.execute_input":"2024-05-11T21:47:42.382982Z","iopub.status.idle":"2024-05-11T21:47:42.392448Z","shell.execute_reply.started":"2024-05-11T21:47:42.382959Z","shell.execute_reply":"2024-05-11T21:47:42.391562Z"},"trusted":true},"execution_count":62,"outputs":[{"execution_count":62,"output_type":"execute_result","data":{"text/plain":"array([ True,  True,  True])"},"metadata":{}}]},{"cell_type":"code","source":"# Data Splitting\nfrom sklearn.model_selection import train_test_split\n\ntrain_images, validation_images, train_labels, validation_labels = train_test_split(train_dataframe['image_path'].values, train_dataframe['label'].values, test_size=0.2, stratify=train_dataframe['label'].values, random_state=42, shuffle=True)\ntest_images, test_labels = test_dataframe['image_path'].values, test_dataframe['label'].values\n","metadata":{"execution":{"iopub.status.busy":"2024-05-11T21:47:42.394876Z","iopub.execute_input":"2024-05-11T21:47:42.395441Z","iopub.status.idle":"2024-05-11T21:47:42.403220Z","shell.execute_reply.started":"2024-05-11T21:47:42.395409Z","shell.execute_reply":"2024-05-11T21:47:42.402407Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"code","source":"print(train_images.shape, train_labels.shape)\nprint(validation_images.shape, validation_labels.shape)\nprint(test_images.shape, test_labels.shape)","metadata":{"execution":{"iopub.status.busy":"2024-05-11T21:47:42.404785Z","iopub.execute_input":"2024-05-11T21:47:42.405139Z","iopub.status.idle":"2024-05-11T21:47:42.418017Z","shell.execute_reply.started":"2024-05-11T21:47:42.405106Z","shell.execute_reply":"2024-05-11T21:47:42.417216Z"},"trusted":true},"execution_count":64,"outputs":[{"name":"stdout","text":"(200,) (200,)\n(51,) (51,)\n(66,) (66,)\n","output_type":"stream"}]},{"cell_type":"code","source":"print(np.unique(train_labels,return_counts=True))\nprint(np.unique(validation_labels,return_counts=True))\nprint(np.unique(test_labels,return_counts=True))","metadata":{"execution":{"iopub.status.busy":"2024-05-11T21:47:42.419050Z","iopub.execute_input":"2024-05-11T21:47:42.419313Z","iopub.status.idle":"2024-05-11T21:47:42.429394Z","shell.execute_reply.started":"2024-05-11T21:47:42.419282Z","shell.execute_reply":"2024-05-11T21:47:42.428533Z"},"trusted":true},"execution_count":65,"outputs":[{"name":"stdout","text":"(array([0, 1, 2]), array([56, 88, 56]))\n(array([0, 1, 2]), array([14, 23, 14]))\n(array([0, 1, 2]), array([20, 26, 20]))\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nfrom torch import nn, optim\nimport torchvision\nfrom torchvision import models, transforms, datasets\nfrom torchvision.models import VGG16_Weights\nfrom torch.utils.data import DataLoader\nimport numpy as np\nfrom sklearn.metrics import f1_score, precision_score, recall_score, classification_report","metadata":{"execution":{"iopub.status.busy":"2024-05-11T21:53:15.106441Z","iopub.execute_input":"2024-05-11T21:53:15.107305Z","iopub.status.idle":"2024-05-11T21:53:15.112183Z","shell.execute_reply.started":"2024-05-11T21:53:15.107270Z","shell.execute_reply":"2024-05-11T21:53:15.111155Z"},"trusted":true},"execution_count":76,"outputs":[]},{"cell_type":"code","source":"test_images, test_labels = test_dataframe['image_path'].values, test_dataframe['label'].values","metadata":{"execution":{"iopub.status.busy":"2024-05-11T21:53:16.982372Z","iopub.execute_input":"2024-05-11T21:53:16.982749Z","iopub.status.idle":"2024-05-11T21:53:16.987384Z","shell.execute_reply.started":"2024-05-11T21:53:16.982719Z","shell.execute_reply":"2024-05-11T21:53:16.986394Z"},"trusted":true},"execution_count":77,"outputs":[]},{"cell_type":"code","source":"# Define Transformations for Data Augmentation\ntransform = transforms.Compose([\n    transforms.ToPILImage(),\n    transforms.RandomResizedCrop(224),\n    transforms.RandomHorizontalFlip(),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])","metadata":{"execution":{"iopub.status.busy":"2024-05-11T21:53:18.482449Z","iopub.execute_input":"2024-05-11T21:53:18.483056Z","iopub.status.idle":"2024-05-11T21:53:18.488499Z","shell.execute_reply.started":"2024-05-11T21:53:18.483024Z","shell.execute_reply":"2024-05-11T21:53:18.487547Z"},"trusted":true},"execution_count":78,"outputs":[]},{"cell_type":"code","source":"# Model Definition with Corrected Pretrained Argument\nvgg16_model = models.vgg16(pretrained=True)\nfor param in vgg16_model.features.parameters():\n    param.requires_grad = False\nnum_features = vgg16_model.classifier[6].in_features\nvgg16_model.classifier[6] = nn.Linear(num_features, len(np.unique(train_labels)))","metadata":{"execution":{"iopub.status.busy":"2024-05-11T21:53:20.558572Z","iopub.execute_input":"2024-05-11T21:53:20.559220Z","iopub.status.idle":"2024-05-11T21:53:22.180349Z","shell.execute_reply.started":"2024-05-11T21:53:20.559186Z","shell.execute_reply":"2024-05-11T21:53:22.179387Z"},"trusted":true},"execution_count":79,"outputs":[]},{"cell_type":"code","source":"# Loss Function and Optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(vgg16_model.classifier.parameters(), lr=0.01, momentum=0.9)\nscheduler = optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)","metadata":{"execution":{"iopub.status.busy":"2024-05-11T21:53:23.906631Z","iopub.execute_input":"2024-05-11T21:53:23.907387Z","iopub.status.idle":"2024-05-11T21:53:23.912753Z","shell.execute_reply.started":"2024-05-11T21:53:23.907350Z","shell.execute_reply":"2024-05-11T21:53:23.911846Z"},"trusted":true},"execution_count":80,"outputs":[]},{"cell_type":"code","source":"def calculate_metrics(y_true, y_pred):\n    f1 = f1_score(y_true, y_pred, average='macro')\n    precision = precision_score(y_true, y_pred, average='macro')\n    recall = recall_score(y_true, y_pred, average='macro')\n    return f1, precision, recall","metadata":{"execution":{"iopub.status.busy":"2024-05-11T21:53:25.278537Z","iopub.execute_input":"2024-05-11T21:53:25.279287Z","iopub.status.idle":"2024-05-11T21:53:25.284129Z","shell.execute_reply.started":"2024-05-11T21:53:25.279255Z","shell.execute_reply":"2024-05-11T21:53:25.283167Z"},"trusted":true},"execution_count":81,"outputs":[]},{"cell_type":"code","source":"# Training and Evaluation Functions\ndef train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n    for epoch in range(num_epochs):\n        model.train()\n        true_labels, predictions = [], []\n        for image_paths, labels in DataLoader(list(zip(train_images, train_labels)), batch_size=32, shuffle=True):\n            inputs = torch.stack([transform(preprocess(path)) for path in image_paths])\n            labels = torch.from_numpy(np.array(labels))\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n            _, preds = torch.max(outputs, 1)\n            true_labels.extend(labels.tolist())\n            predictions.extend(preds.tolist())\n\n        scheduler.step()\n        f1, precision, recall = calculate_metrics(true_labels, predictions)\n        print(f'Epoch {epoch+1}/{num_epochs}: F1={f1:.2f}, Precision={precision:.2f}, Recall={recall:.2f}')","metadata":{"execution":{"iopub.status.busy":"2024-05-11T21:53:31.138828Z","iopub.execute_input":"2024-05-11T21:53:31.139648Z","iopub.status.idle":"2024-05-11T21:53:31.147490Z","shell.execute_reply.started":"2024-05-11T21:53:31.139617Z","shell.execute_reply":"2024-05-11T21:53:31.146470Z"},"trusted":true},"execution_count":84,"outputs":[]},{"cell_type":"code","source":"def evaluate_model(model, image_paths, labels):\n    model.eval()\n    true_labels, predictions = [], []\n    inputs = torch.stack([transform(preprocess(path)) for path in image_paths])\n    labels = torch.from_numpy(np.array(labels))\n    outputs = model(inputs)\n    _, predicted = torch.max(outputs.data, 1)\n    true_labels.extend(labels.tolist())\n    predictions.extend(predicted.tolist())\n\n    f1, precision, recall = calculate_metrics(true_labels, predictions)\n    cr = classification_report(true_labels, predictions)\n    print(f'Accuracy: {100 * sum(np.array(true_labels) == np.array(predictions)) / len(labels):.2f}%')\n    print(f'Classification Report:\\n{cr}')","metadata":{"execution":{"iopub.status.busy":"2024-05-11T21:53:40.230922Z","iopub.execute_input":"2024-05-11T21:53:40.231608Z","iopub.status.idle":"2024-05-11T21:53:40.238413Z","shell.execute_reply.started":"2024-05-11T21:53:40.231578Z","shell.execute_reply":"2024-05-11T21:53:40.237419Z"},"trusted":true},"execution_count":85,"outputs":[]},{"cell_type":"code","source":"if __name__ == '__main__':\n    train_model(vgg16_model, criterion, optimizer, scheduler, num_epochs=25)\n    evaluate_model(vgg16_model, test_images, test_labels)","metadata":{"execution":{"iopub.status.busy":"2024-05-11T21:53:48.030763Z","iopub.execute_input":"2024-05-11T21:53:48.031172Z","iopub.status.idle":"2024-05-11T21:54:51.204780Z","shell.execute_reply.started":"2024-05-11T21:53:48.031142Z","shell.execute_reply":"2024-05-11T21:54:51.203139Z"},"trusted":true},"execution_count":86,"outputs":[{"name":"stdout","text":"Epoch 1/25: F1=0.53, Precision=0.53, Recall=0.53\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[86], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m----> 2\u001b[0m     \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvgg16_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m25\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m     evaluate_model(vgg16_model, test_images, test_labels)\n","Cell \u001b[0;32mIn[84], line 10\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, criterion, optimizer, scheduler, num_epochs)\u001b[0m\n\u001b[1;32m      8\u001b[0m labels \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(np\u001b[38;5;241m.\u001b[39marray(labels))\n\u001b[1;32m      9\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 10\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[1;32m     12\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torchvision/models/vgg.py:66\u001b[0m, in \u001b[0;36mVGG.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[0;32m---> 66\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mavgpool(x)\n\u001b[1;32m     68\u001b[0m     x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mflatten(x, \u001b[38;5;241m1\u001b[39m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/container.py:215\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 215\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/conv.py:460\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 460\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/conv.py:456\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    454\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    455\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 456\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]}]}